{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22305,
     "status": "ok",
     "timestamp": 1625049812187,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "vSfZS4V-HJXi",
    "outputId": "51032bf6-90ce-478e-e7b7-454f3ba07305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive,files\n",
    "drive.mount(\"/content/gdrive\", force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1625049812572,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "MnOPm0FLH1S3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/gdrive/My Drive/2/Mask_RCNN_TF2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1625049826982,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "ZbhoPojrIOn6"
   },
   "outputs": [],
   "source": [
    "# !pip install --quiet --upgrade -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1487,
     "status": "ok",
     "timestamp": 1625049830731,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "ocp09V7OINoX",
    "outputId": "967488a0-42e9-41ce-f6b1-3109d7fbc541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "# import keras\n",
    "# print(keras.__version__)\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1625049831535,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "cBzfMt83OI0r",
    "outputId": "8ec2dc39-9522-4d15-cbbc-d9da5a162c4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3272,
     "status": "ok",
     "timestamp": 1625049835112,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "5xXOjRInH88_"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./mrcnn\")  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1625049835113,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "fCd4n74DJR2k"
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = './'\n",
    "DATA_DIR = './datasets/fruits2'\n",
    "DEFAULT_LOGS_DIR = './assets/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27041,
     "status": "ok",
     "timestamp": 1625049862149,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "tAkd1wHAa-PI",
    "outputId": "04ba2560-d613-469a-d398-55839a6309ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(os.path.join(DATA_DIR, \"train-images\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1625049862150,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "gQfhB-1PH1Vc",
    "outputId": "cea31516-fcae-471f-aacd-1497d0023198"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO weights already exists\n"
     ]
    }
   ],
   "source": [
    "# Local path to trained weights file\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_WEIGHTS_PATH):\n",
    "    utils.download_trained_weights(COCO_WEIGHTS_PATH)\n",
    "else:\n",
    "    print(\"COCO weights already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1625049862150,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "l7KCwhUEH1YB"
   },
   "outputs": [],
   "source": [
    "class BalloonConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"fruits2-\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU =   1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + baloon\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 200\n",
    "\n",
    "    # Skip detections with the following confidence level\n",
    "    DETECTION_MIN_CONFIDENCE = 0.90\n",
    "\n",
    "    # Initial weights\n",
    "    # INIT_IT = \"imagenet\"\n",
    "    INIT_IT = \"last\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1625049862151,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "slcI2pfBH1aJ"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "#  Dataset\n",
    "############################################################\n",
    "\n",
    "class BalloonDataset(utils.Dataset):\n",
    "\n",
    "    def load_balloon(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the Balloon dataset.\n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "        # Add classes. We have only one class to add.\n",
    "        self.add_class(\"balloon\", 1, \"balloon\")\n",
    "\n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"train-images\", \"val-images\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        # Load annotations\n",
    "        # VGG Image Annotator saves each image in the form:\n",
    "        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n",
    "        #   'regions': {\n",
    "        #       '0': {\n",
    "        #           'region_attributes': {},\n",
    "        #           'shape_attributes': {\n",
    "        #               'all_points_x': [...],\n",
    "        #               'all_points_y': [...],\n",
    "        #               'name': 'polygon'}},\n",
    "        #       ... more regions ...\n",
    "        #   },\n",
    "        #   'size': 100202\n",
    "        # }\n",
    "\n",
    "        # We mostly care about the x and y coordinates of each region\n",
    "        annotations = json.load(open(os.path.join(dataset_dir, \"via_project_fruits.json\")))\n",
    "        annotations = list(annotations.values())  # don't need the dict keys\n",
    "\n",
    "        # The VIA tool saves images in the JSON even if they don't have any\n",
    "        # annotations. Skip unannotated images.\n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "        # Add images\n",
    "        for a in annotations:\n",
    "            # Get the x, y coordinaets of points of the polygons that make up\n",
    "            # the outline of each object instance. There are stores in the\n",
    "            # shape_attributes (see json format above)\n",
    "            polygons = [r['shape_attributes'] for r in a['regions']]\n",
    "            # load_mask() needs the image size to convert polygons to masks.\n",
    "            # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
    "            # the image. This is only managable since the dataset is tiny.\n",
    "\n",
    "            image_path = os.path.join(dataset_dir, a['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "            \n",
    "            self.add_image(\n",
    "                \"balloon\",\n",
    "                image_id=a['filename'],  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                polygons=polygons)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"\n",
    "        Generate instance masks for an image.\n",
    "        Returns:\n",
    "            masks: A bool array of shape [height, width, instance count] with\n",
    "                one mask per instance.\n",
    "            class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a balloon dataset image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"balloon\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        return mask, np.ones([mask.shape[-1]], dtype=np.float32) #dtype=np.int32\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"balloon\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1426613,
     "status": "ok",
     "timestamp": 1625051288756,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "Z2aKWNIcH1cf"
   },
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = BalloonDataset()\n",
    "dataset_train.load_balloon(DATA_DIR, \"train-images\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = BalloonDataset()\n",
    "dataset_val.load_balloon(DATA_DIR, \"val-images\")\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cRtPMczKXvi",
    "outputId": "5abce327-8458-4fac-d1ec-545686b8ebe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 1s 0us/step\n",
      "94666752/94653016 [==============================] - 1s 0us/step\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: ./assets/logs/fruits2-20210630T1108/mask_rcnn_fruits2-_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (ConstLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_2:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_5:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_8:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_11:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_2:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_5:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_8:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_11:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - ETA: 0s - batch: 99.5000 - size: 1.0000 - loss: 1.9602 - rpn_class_loss: 0.1997 - rpn_bbox_loss: 0.6176 - mrcnn_class_loss: 0.1352 - mrcnn_bbox_loss: 0.5267 - mrcnn_mask_loss: 0.4809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 267s 994ms/step - batch: 99.5000 - size: 1.0000 - loss: 1.9602 - rpn_class_loss: 0.1997 - rpn_bbox_loss: 0.6176 - mrcnn_class_loss: 0.1352 - mrcnn_bbox_loss: 0.5267 - mrcnn_mask_loss: 0.4809 - val_loss: 1.7116 - val_rpn_class_loss: 0.1426 - val_rpn_bbox_loss: 0.3665 - val_mrcnn_class_loss: 0.1669 - val_mrcnn_bbox_loss: 0.4796 - val_mrcnn_mask_loss: 0.5559\n",
      "Epoch 2/400\n",
      "200/200 [==============================] - 171s 857ms/step - batch: 99.5000 - size: 1.0000 - loss: 1.6011 - rpn_class_loss: 0.1508 - rpn_bbox_loss: 0.3992 - mrcnn_class_loss: 0.1539 - mrcnn_bbox_loss: 0.4086 - mrcnn_mask_loss: 0.4886 - val_loss: 1.5616 - val_rpn_class_loss: 0.1443 - val_rpn_bbox_loss: 0.4038 - val_mrcnn_class_loss: 0.1460 - val_mrcnn_bbox_loss: 0.3824 - val_mrcnn_mask_loss: 0.4852\n",
      "Epoch 3/400\n",
      "200/200 [==============================] - 172s 861ms/step - batch: 99.5000 - size: 1.0000 - loss: 1.4582 - rpn_class_loss: 0.1079 - rpn_bbox_loss: 0.3322 - mrcnn_class_loss: 0.1851 - mrcnn_bbox_loss: 0.3650 - mrcnn_mask_loss: 0.4680 - val_loss: 1.3300 - val_rpn_class_loss: 0.1235 - val_rpn_bbox_loss: 0.2960 - val_mrcnn_class_loss: 0.1597 - val_mrcnn_bbox_loss: 0.3084 - val_mrcnn_mask_loss: 0.4423\n",
      "Epoch 4/400\n",
      "200/200 [==============================] - 172s 861ms/step - batch: 99.5000 - size: 1.0000 - loss: 1.3419 - rpn_class_loss: 0.0901 - rpn_bbox_loss: 0.3122 - mrcnn_class_loss: 0.1848 - mrcnn_bbox_loss: 0.3165 - mrcnn_mask_loss: 0.4384 - val_loss: 1.3820 - val_rpn_class_loss: 0.0666 - val_rpn_bbox_loss: 0.3642 - val_mrcnn_class_loss: 0.1594 - val_mrcnn_bbox_loss: 0.3323 - val_mrcnn_mask_loss: 0.4594\n",
      "Epoch 5/400\n",
      "200/200 [==============================] - 173s 865ms/step - batch: 99.5000 - size: 1.0000 - loss: 1.1877 - rpn_class_loss: 0.0592 - rpn_bbox_loss: 0.2616 - mrcnn_class_loss: 0.1961 - mrcnn_bbox_loss: 0.2721 - mrcnn_mask_loss: 0.3988 - val_loss: 1.1665 - val_rpn_class_loss: 0.0465 - val_rpn_bbox_loss: 0.2760 - val_mrcnn_class_loss: 0.1992 - val_mrcnn_bbox_loss: 0.2627 - val_mrcnn_mask_loss: 0.3822\n",
      "Epoch 6/400\n",
      "200/200 [==============================] - 172s 861ms/step - batch: 99.5000 - size: 1.0000 - loss: 1.1004 - rpn_class_loss: 0.0500 - rpn_bbox_loss: 0.2248 - mrcnn_class_loss: 0.1918 - mrcnn_bbox_loss: 0.2531 - mrcnn_mask_loss: 0.3807 - val_loss: 1.0037 - val_rpn_class_loss: 0.0383 - val_rpn_bbox_loss: 0.1979 - val_mrcnn_class_loss: 0.1717 - val_mrcnn_bbox_loss: 0.2482 - val_mrcnn_mask_loss: 0.3476\n",
      "Epoch 7/400\n",
      "200/200 [==============================] - 173s 865ms/step - batch: 99.5000 - size: 1.0000 - loss: 1.1219 - rpn_class_loss: 0.0485 - rpn_bbox_loss: 0.2469 - mrcnn_class_loss: 0.1803 - mrcnn_bbox_loss: 0.2671 - mrcnn_mask_loss: 0.3790 - val_loss: 1.0149 - val_rpn_class_loss: 0.0405 - val_rpn_bbox_loss: 0.2209 - val_mrcnn_class_loss: 0.1686 - val_mrcnn_bbox_loss: 0.2256 - val_mrcnn_mask_loss: 0.3592\n",
      "Epoch 8/400\n",
      "200/200 [==============================] - 171s 854ms/step - batch: 99.5000 - size: 1.0000 - loss: 1.0134 - rpn_class_loss: 0.0425 - rpn_bbox_loss: 0.2094 - mrcnn_class_loss: 0.1758 - mrcnn_bbox_loss: 0.2299 - mrcnn_mask_loss: 0.3558 - val_loss: 0.9730 - val_rpn_class_loss: 0.0403 - val_rpn_bbox_loss: 0.2112 - val_mrcnn_class_loss: 0.1542 - val_mrcnn_bbox_loss: 0.2416 - val_mrcnn_mask_loss: 0.3257\n",
      "Epoch 9/400\n",
      "200/200 [==============================] - 174s 872ms/step - batch: 99.5000 - size: 1.0000 - loss: 1.0043 - rpn_class_loss: 0.0377 - rpn_bbox_loss: 0.1987 - mrcnn_class_loss: 0.2002 - mrcnn_bbox_loss: 0.2263 - mrcnn_mask_loss: 0.3415 - val_loss: 0.9140 - val_rpn_class_loss: 0.0269 - val_rpn_bbox_loss: 0.1748 - val_mrcnn_class_loss: 0.1697 - val_mrcnn_bbox_loss: 0.2056 - val_mrcnn_mask_loss: 0.3369\n",
      "Epoch 10/400\n",
      "200/200 [==============================] - 174s 869ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.9375 - rpn_class_loss: 0.0349 - rpn_bbox_loss: 0.1981 - mrcnn_class_loss: 0.1651 - mrcnn_bbox_loss: 0.2128 - mrcnn_mask_loss: 0.3267 - val_loss: 0.9315 - val_rpn_class_loss: 0.0346 - val_rpn_bbox_loss: 0.1743 - val_mrcnn_class_loss: 0.2041 - val_mrcnn_bbox_loss: 0.2033 - val_mrcnn_mask_loss: 0.3151\n",
      "Epoch 11/400\n",
      "200/200 [==============================] - 173s 863ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.9577 - rpn_class_loss: 0.0491 - rpn_bbox_loss: 0.1935 - mrcnn_class_loss: 0.1739 - mrcnn_bbox_loss: 0.2144 - mrcnn_mask_loss: 0.3268 - val_loss: 0.9114 - val_rpn_class_loss: 0.0303 - val_rpn_bbox_loss: 0.2208 - val_mrcnn_class_loss: 0.1280 - val_mrcnn_bbox_loss: 0.2098 - val_mrcnn_mask_loss: 0.3224\n",
      "Epoch 12/400\n",
      "200/200 [==============================] - 173s 866ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.8803 - rpn_class_loss: 0.0279 - rpn_bbox_loss: 0.1714 - mrcnn_class_loss: 0.1764 - mrcnn_bbox_loss: 0.1945 - mrcnn_mask_loss: 0.3101 - val_loss: 0.8811 - val_rpn_class_loss: 0.0322 - val_rpn_bbox_loss: 0.1614 - val_mrcnn_class_loss: 0.1811 - val_mrcnn_bbox_loss: 0.1955 - val_mrcnn_mask_loss: 0.3110\n",
      "Epoch 13/400\n",
      "200/200 [==============================] - 173s 867ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.8849 - rpn_class_loss: 0.0287 - rpn_bbox_loss: 0.1772 - mrcnn_class_loss: 0.1649 - mrcnn_bbox_loss: 0.1997 - mrcnn_mask_loss: 0.3143 - val_loss: 0.9228 - val_rpn_class_loss: 0.0314 - val_rpn_bbox_loss: 0.2196 - val_mrcnn_class_loss: 0.1546 - val_mrcnn_bbox_loss: 0.2070 - val_mrcnn_mask_loss: 0.3102\n",
      "Epoch 14/400\n",
      "200/200 [==============================] - 173s 864ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.8635 - rpn_class_loss: 0.0287 - rpn_bbox_loss: 0.1695 - mrcnn_class_loss: 0.1737 - mrcnn_bbox_loss: 0.1860 - mrcnn_mask_loss: 0.3056 - val_loss: 0.9399 - val_rpn_class_loss: 0.0906 - val_rpn_bbox_loss: 0.2121 - val_mrcnn_class_loss: 0.1574 - val_mrcnn_bbox_loss: 0.1873 - val_mrcnn_mask_loss: 0.2925\n",
      "Epoch 15/400\n",
      "200/200 [==============================] - 174s 872ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.8507 - rpn_class_loss: 0.0285 - rpn_bbox_loss: 0.1647 - mrcnn_class_loss: 0.1638 - mrcnn_bbox_loss: 0.1862 - mrcnn_mask_loss: 0.3074 - val_loss: 0.8682 - val_rpn_class_loss: 0.0266 - val_rpn_bbox_loss: 0.1640 - val_mrcnn_class_loss: 0.1885 - val_mrcnn_bbox_loss: 0.1841 - val_mrcnn_mask_loss: 0.3051\n",
      "Epoch 16/400\n",
      "200/200 [==============================] - 172s 859ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.8216 - rpn_class_loss: 0.0251 - rpn_bbox_loss: 0.1677 - mrcnn_class_loss: 0.1539 - mrcnn_bbox_loss: 0.1779 - mrcnn_mask_loss: 0.2971 - val_loss: 0.7541 - val_rpn_class_loss: 0.0257 - val_rpn_bbox_loss: 0.1333 - val_mrcnn_class_loss: 0.1595 - val_mrcnn_bbox_loss: 0.1622 - val_mrcnn_mask_loss: 0.2733\n",
      "Epoch 17/400\n",
      "200/200 [==============================] - 174s 873ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.8721 - rpn_class_loss: 0.0281 - rpn_bbox_loss: 0.1628 - mrcnn_class_loss: 0.1835 - mrcnn_bbox_loss: 0.1913 - mrcnn_mask_loss: 0.3065 - val_loss: 0.8525 - val_rpn_class_loss: 0.0230 - val_rpn_bbox_loss: 0.1674 - val_mrcnn_class_loss: 0.1767 - val_mrcnn_bbox_loss: 0.1915 - val_mrcnn_mask_loss: 0.2939\n",
      "Epoch 18/400\n",
      "200/200 [==============================] - 173s 867ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.8026 - rpn_class_loss: 0.0323 - rpn_bbox_loss: 0.1599 - mrcnn_class_loss: 0.1535 - mrcnn_bbox_loss: 0.1709 - mrcnn_mask_loss: 0.2859 - val_loss: 0.8424 - val_rpn_class_loss: 0.0359 - val_rpn_bbox_loss: 0.1843 - val_mrcnn_class_loss: 0.1564 - val_mrcnn_bbox_loss: 0.1741 - val_mrcnn_mask_loss: 0.2917\n",
      "Epoch 19/400\n",
      "200/200 [==============================] - 172s 863ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.7737 - rpn_class_loss: 0.0252 - rpn_bbox_loss: 0.1516 - mrcnn_class_loss: 0.1574 - mrcnn_bbox_loss: 0.1598 - mrcnn_mask_loss: 0.2797 - val_loss: 0.8006 - val_rpn_class_loss: 0.0311 - val_rpn_bbox_loss: 0.1461 - val_mrcnn_class_loss: 0.1719 - val_mrcnn_bbox_loss: 0.1715 - val_mrcnn_mask_loss: 0.2799\n",
      "Epoch 20/400\n",
      "200/200 [==============================] - 173s 865ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.7946 - rpn_class_loss: 0.0216 - rpn_bbox_loss: 0.1542 - mrcnn_class_loss: 0.1653 - mrcnn_bbox_loss: 0.1694 - mrcnn_mask_loss: 0.2841 - val_loss: 0.7877 - val_rpn_class_loss: 0.0200 - val_rpn_bbox_loss: 0.1665 - val_mrcnn_class_loss: 0.1463 - val_mrcnn_bbox_loss: 0.1710 - val_mrcnn_mask_loss: 0.2839\n",
      "Epoch 21/400\n",
      "200/200 [==============================] - 175s 874ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.7452 - rpn_class_loss: 0.0238 - rpn_bbox_loss: 0.1474 - mrcnn_class_loss: 0.1472 - mrcnn_bbox_loss: 0.1507 - mrcnn_mask_loss: 0.2761 - val_loss: 0.6566 - val_rpn_class_loss: 0.0122 - val_rpn_bbox_loss: 0.1524 - val_mrcnn_class_loss: 0.0815 - val_mrcnn_bbox_loss: 0.1383 - val_mrcnn_mask_loss: 0.2721\n",
      "Epoch 22/400\n",
      "200/200 [==============================] - 178s 891ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.7704 - rpn_class_loss: 0.0231 - rpn_bbox_loss: 0.1515 - mrcnn_class_loss: 0.1448 - mrcnn_bbox_loss: 0.1640 - mrcnn_mask_loss: 0.2870 - val_loss: 0.7683 - val_rpn_class_loss: 0.0193 - val_rpn_bbox_loss: 0.1407 - val_mrcnn_class_loss: 0.1632 - val_mrcnn_bbox_loss: 0.1680 - val_mrcnn_mask_loss: 0.2771\n",
      "Epoch 23/400\n",
      "200/200 [==============================] - 175s 875ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.7964 - rpn_class_loss: 0.0214 - rpn_bbox_loss: 0.1529 - mrcnn_class_loss: 0.1651 - mrcnn_bbox_loss: 0.1682 - mrcnn_mask_loss: 0.2888 - val_loss: 0.7451 - val_rpn_class_loss: 0.0207 - val_rpn_bbox_loss: 0.1867 - val_mrcnn_class_loss: 0.1111 - val_mrcnn_bbox_loss: 0.1532 - val_mrcnn_mask_loss: 0.2735\n",
      "Epoch 24/400\n",
      "200/200 [==============================] - 174s 868ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.7108 - rpn_class_loss: 0.0195 - rpn_bbox_loss: 0.1374 - mrcnn_class_loss: 0.1347 - mrcnn_bbox_loss: 0.1500 - mrcnn_mask_loss: 0.2692 - val_loss: 0.7583 - val_rpn_class_loss: 0.0218 - val_rpn_bbox_loss: 0.1527 - val_mrcnn_class_loss: 0.1287 - val_mrcnn_bbox_loss: 0.1788 - val_mrcnn_mask_loss: 0.2762\n",
      "Epoch 25/400\n",
      "200/200 [==============================] - 179s 896ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.6933 - rpn_class_loss: 0.0191 - rpn_bbox_loss: 0.1312 - mrcnn_class_loss: 0.1287 - mrcnn_bbox_loss: 0.1438 - mrcnn_mask_loss: 0.2704 - val_loss: 0.7921 - val_rpn_class_loss: 0.0249 - val_rpn_bbox_loss: 0.1668 - val_mrcnn_class_loss: 0.1486 - val_mrcnn_bbox_loss: 0.1688 - val_mrcnn_mask_loss: 0.2830\n",
      "Epoch 26/400\n",
      "200/200 [==============================] - 176s 882ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.6724 - rpn_class_loss: 0.0171 - rpn_bbox_loss: 0.1286 - mrcnn_class_loss: 0.1201 - mrcnn_bbox_loss: 0.1455 - mrcnn_mask_loss: 0.2611 - val_loss: 0.6870 - val_rpn_class_loss: 0.0160 - val_rpn_bbox_loss: 0.1515 - val_mrcnn_class_loss: 0.1139 - val_mrcnn_bbox_loss: 0.1444 - val_mrcnn_mask_loss: 0.2612\n",
      "Epoch 27/400\n",
      "200/200 [==============================] - 177s 884ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.6835 - rpn_class_loss: 0.0190 - rpn_bbox_loss: 0.1327 - mrcnn_class_loss: 0.1265 - mrcnn_bbox_loss: 0.1406 - mrcnn_mask_loss: 0.2648 - val_loss: 0.6797 - val_rpn_class_loss: 0.0246 - val_rpn_bbox_loss: 0.1317 - val_mrcnn_class_loss: 0.1258 - val_mrcnn_bbox_loss: 0.1467 - val_mrcnn_mask_loss: 0.2509\n",
      "Epoch 28/400\n",
      "200/200 [==============================] - 176s 878ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.7543 - rpn_class_loss: 0.0203 - rpn_bbox_loss: 0.1510 - mrcnn_class_loss: 0.1424 - mrcnn_bbox_loss: 0.1618 - mrcnn_mask_loss: 0.2788 - val_loss: 0.8047 - val_rpn_class_loss: 0.0214 - val_rpn_bbox_loss: 0.1769 - val_mrcnn_class_loss: 0.1478 - val_mrcnn_bbox_loss: 0.1753 - val_mrcnn_mask_loss: 0.2833\n",
      "Epoch 29/400\n",
      "200/200 [==============================] - 175s 877ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.6815 - rpn_class_loss: 0.0166 - rpn_bbox_loss: 0.1290 - mrcnn_class_loss: 0.1308 - mrcnn_bbox_loss: 0.1401 - mrcnn_mask_loss: 0.2649 - val_loss: 0.7248 - val_rpn_class_loss: 0.0114 - val_rpn_bbox_loss: 0.1436 - val_mrcnn_class_loss: 0.1345 - val_mrcnn_bbox_loss: 0.1564 - val_mrcnn_mask_loss: 0.2789\n",
      "Epoch 30/400\n",
      "200/200 [==============================] - 176s 879ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.6171 - rpn_class_loss: 0.0159 - rpn_bbox_loss: 0.1166 - mrcnn_class_loss: 0.0999 - mrcnn_bbox_loss: 0.1337 - mrcnn_mask_loss: 0.2510 - val_loss: 0.6366 - val_rpn_class_loss: 0.0151 - val_rpn_bbox_loss: 0.1333 - val_mrcnn_class_loss: 0.0878 - val_mrcnn_bbox_loss: 0.1419 - val_mrcnn_mask_loss: 0.2585\n",
      "Epoch 31/400\n",
      "200/200 [==============================] - 177s 886ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.6348 - rpn_class_loss: 0.0126 - rpn_bbox_loss: 0.1195 - mrcnn_class_loss: 0.1146 - mrcnn_bbox_loss: 0.1320 - mrcnn_mask_loss: 0.2561 - val_loss: 0.6567 - val_rpn_class_loss: 0.0158 - val_rpn_bbox_loss: 0.1178 - val_mrcnn_class_loss: 0.1187 - val_mrcnn_bbox_loss: 0.1517 - val_mrcnn_mask_loss: 0.2527\n",
      "Epoch 32/400\n",
      "200/200 [==============================] - 176s 882ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.6306 - rpn_class_loss: 0.0125 - rpn_bbox_loss: 0.1182 - mrcnn_class_loss: 0.1085 - mrcnn_bbox_loss: 0.1338 - mrcnn_mask_loss: 0.2577 - val_loss: 0.7683 - val_rpn_class_loss: 0.0649 - val_rpn_bbox_loss: 0.1589 - val_mrcnn_class_loss: 0.1345 - val_mrcnn_bbox_loss: 0.1490 - val_mrcnn_mask_loss: 0.2610\n",
      "Epoch 33/400\n",
      "200/200 [==============================] - 180s 899ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.6447 - rpn_class_loss: 0.0165 - rpn_bbox_loss: 0.1220 - mrcnn_class_loss: 0.1067 - mrcnn_bbox_loss: 0.1339 - mrcnn_mask_loss: 0.2656 - val_loss: 0.6909 - val_rpn_class_loss: 0.0166 - val_rpn_bbox_loss: 0.1618 - val_mrcnn_class_loss: 0.1203 - val_mrcnn_bbox_loss: 0.1419 - val_mrcnn_mask_loss: 0.2503\n",
      "Epoch 34/400\n",
      "200/200 [==============================] - 177s 887ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.6648 - rpn_class_loss: 0.0139 - rpn_bbox_loss: 0.1344 - mrcnn_class_loss: 0.1226 - mrcnn_bbox_loss: 0.1373 - mrcnn_mask_loss: 0.2566 - val_loss: 0.6437 - val_rpn_class_loss: 0.0171 - val_rpn_bbox_loss: 0.1681 - val_mrcnn_class_loss: 0.0868 - val_mrcnn_bbox_loss: 0.1271 - val_mrcnn_mask_loss: 0.2445\n",
      "Epoch 35/400\n",
      "200/200 [==============================] - 177s 885ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.6340 - rpn_class_loss: 0.0143 - rpn_bbox_loss: 0.1241 - mrcnn_class_loss: 0.1163 - mrcnn_bbox_loss: 0.1283 - mrcnn_mask_loss: 0.2509 - val_loss: 0.6340 - val_rpn_class_loss: 0.0183 - val_rpn_bbox_loss: 0.1299 - val_mrcnn_class_loss: 0.1137 - val_mrcnn_bbox_loss: 0.1256 - val_mrcnn_mask_loss: 0.2465\n",
      "Epoch 36/400\n",
      "200/200 [==============================] - 178s 893ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.6390 - rpn_class_loss: 0.0139 - rpn_bbox_loss: 0.1205 - mrcnn_class_loss: 0.1129 - mrcnn_bbox_loss: 0.1330 - mrcnn_mask_loss: 0.2587 - val_loss: 0.6709 - val_rpn_class_loss: 0.0236 - val_rpn_bbox_loss: 0.1515 - val_mrcnn_class_loss: 0.0980 - val_mrcnn_bbox_loss: 0.1433 - val_mrcnn_mask_loss: 0.2546\n",
      "Epoch 37/400\n",
      "200/200 [==============================] - 176s 882ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5792 - rpn_class_loss: 0.0103 - rpn_bbox_loss: 0.1101 - mrcnn_class_loss: 0.0972 - mrcnn_bbox_loss: 0.1194 - mrcnn_mask_loss: 0.2422 - val_loss: 0.7877 - val_rpn_class_loss: 0.0314 - val_rpn_bbox_loss: 0.2099 - val_mrcnn_class_loss: 0.1028 - val_mrcnn_bbox_loss: 0.1602 - val_mrcnn_mask_loss: 0.2834\n",
      "Epoch 38/400\n",
      "200/200 [==============================] - 177s 883ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5997 - rpn_class_loss: 0.0097 - rpn_bbox_loss: 0.1132 - mrcnn_class_loss: 0.1023 - mrcnn_bbox_loss: 0.1259 - mrcnn_mask_loss: 0.2486 - val_loss: 0.6123 - val_rpn_class_loss: 0.0142 - val_rpn_bbox_loss: 0.1609 - val_mrcnn_class_loss: 0.0740 - val_mrcnn_bbox_loss: 0.1258 - val_mrcnn_mask_loss: 0.2375\n",
      "Epoch 39/400\n",
      "200/200 [==============================] - 180s 900ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.6124 - rpn_class_loss: 0.0140 - rpn_bbox_loss: 0.1193 - mrcnn_class_loss: 0.1002 - mrcnn_bbox_loss: 0.1265 - mrcnn_mask_loss: 0.2523 - val_loss: 0.8522 - val_rpn_class_loss: 0.0571 - val_rpn_bbox_loss: 0.1715 - val_mrcnn_class_loss: 0.1688 - val_mrcnn_bbox_loss: 0.1757 - val_mrcnn_mask_loss: 0.2790\n",
      "Epoch 40/400\n",
      "200/200 [==============================] - 179s 894ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.6120 - rpn_class_loss: 0.0229 - rpn_bbox_loss: 0.1200 - mrcnn_class_loss: 0.1075 - mrcnn_bbox_loss: 0.1211 - mrcnn_mask_loss: 0.2404 - val_loss: 0.6477 - val_rpn_class_loss: 0.0110 - val_rpn_bbox_loss: 0.1425 - val_mrcnn_class_loss: 0.0931 - val_mrcnn_bbox_loss: 0.1334 - val_mrcnn_mask_loss: 0.2677\n",
      "Epoch 41/400\n",
      "200/200 [==============================] - 182s 911ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.6779 - rpn_class_loss: 0.0157 - rpn_bbox_loss: 0.1392 - mrcnn_class_loss: 0.1115 - mrcnn_bbox_loss: 0.1423 - mrcnn_mask_loss: 0.2693 - val_loss: 0.7192 - val_rpn_class_loss: 0.0201 - val_rpn_bbox_loss: 0.1462 - val_mrcnn_class_loss: 0.1197 - val_mrcnn_bbox_loss: 0.1607 - val_mrcnn_mask_loss: 0.2725\n",
      "Epoch 42/400\n",
      "200/200 [==============================] - 174s 868ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5800 - rpn_class_loss: 0.0136 - rpn_bbox_loss: 0.1037 - mrcnn_class_loss: 0.1035 - mrcnn_bbox_loss: 0.1176 - mrcnn_mask_loss: 0.2415 - val_loss: 0.5667 - val_rpn_class_loss: 0.0137 - val_rpn_bbox_loss: 0.1284 - val_mrcnn_class_loss: 0.0652 - val_mrcnn_bbox_loss: 0.1250 - val_mrcnn_mask_loss: 0.2345\n",
      "Epoch 43/400\n",
      "200/200 [==============================] - 178s 889ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5890 - rpn_class_loss: 0.0136 - rpn_bbox_loss: 0.1180 - mrcnn_class_loss: 0.0988 - mrcnn_bbox_loss: 0.1171 - mrcnn_mask_loss: 0.2416 - val_loss: 0.7063 - val_rpn_class_loss: 0.0509 - val_rpn_bbox_loss: 0.1613 - val_mrcnn_class_loss: 0.1004 - val_mrcnn_bbox_loss: 0.1325 - val_mrcnn_mask_loss: 0.2613\n",
      "Epoch 44/400\n",
      "200/200 [==============================] - 176s 880ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5639 - rpn_class_loss: 0.0129 - rpn_bbox_loss: 0.1065 - mrcnn_class_loss: 0.0933 - mrcnn_bbox_loss: 0.1137 - mrcnn_mask_loss: 0.2375 - val_loss: 0.7118 - val_rpn_class_loss: 0.0177 - val_rpn_bbox_loss: 0.1509 - val_mrcnn_class_loss: 0.1180 - val_mrcnn_bbox_loss: 0.1559 - val_mrcnn_mask_loss: 0.2694\n",
      "Epoch 45/400\n",
      "200/200 [==============================] - 180s 900ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5796 - rpn_class_loss: 0.0129 - rpn_bbox_loss: 0.1066 - mrcnn_class_loss: 0.1012 - mrcnn_bbox_loss: 0.1166 - mrcnn_mask_loss: 0.2422 - val_loss: 0.7070 - val_rpn_class_loss: 0.0143 - val_rpn_bbox_loss: 0.1308 - val_mrcnn_class_loss: 0.1296 - val_mrcnn_bbox_loss: 0.1521 - val_mrcnn_mask_loss: 0.2801\n",
      "Epoch 46/400\n",
      "200/200 [==============================] - 176s 879ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5353 - rpn_class_loss: 0.0093 - rpn_bbox_loss: 0.0979 - mrcnn_class_loss: 0.0852 - mrcnn_bbox_loss: 0.1088 - mrcnn_mask_loss: 0.2341 - val_loss: 0.6996 - val_rpn_class_loss: 0.0270 - val_rpn_bbox_loss: 0.1546 - val_mrcnn_class_loss: 0.1009 - val_mrcnn_bbox_loss: 0.1574 - val_mrcnn_mask_loss: 0.2597\n",
      "Epoch 47/400\n",
      "200/200 [==============================] - 178s 890ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5611 - rpn_class_loss: 0.0097 - rpn_bbox_loss: 0.1073 - mrcnn_class_loss: 0.0914 - mrcnn_bbox_loss: 0.1135 - mrcnn_mask_loss: 0.2392 - val_loss: 0.5959 - val_rpn_class_loss: 0.0109 - val_rpn_bbox_loss: 0.1033 - val_mrcnn_class_loss: 0.0866 - val_mrcnn_bbox_loss: 0.1391 - val_mrcnn_mask_loss: 0.2560\n",
      "Epoch 48/400\n",
      "200/200 [==============================] - 180s 902ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5441 - rpn_class_loss: 0.0112 - rpn_bbox_loss: 0.1027 - mrcnn_class_loss: 0.0843 - mrcnn_bbox_loss: 0.1117 - mrcnn_mask_loss: 0.2342 - val_loss: 0.5953 - val_rpn_class_loss: 0.0175 - val_rpn_bbox_loss: 0.1230 - val_mrcnn_class_loss: 0.0820 - val_mrcnn_bbox_loss: 0.1261 - val_mrcnn_mask_loss: 0.2467\n",
      "Epoch 49/400\n",
      "200/200 [==============================] - 186s 929ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5742 - rpn_class_loss: 0.0134 - rpn_bbox_loss: 0.1113 - mrcnn_class_loss: 0.0946 - mrcnn_bbox_loss: 0.1200 - mrcnn_mask_loss: 0.2350 - val_loss: 0.6587 - val_rpn_class_loss: 0.0164 - val_rpn_bbox_loss: 0.1623 - val_mrcnn_class_loss: 0.0854 - val_mrcnn_bbox_loss: 0.1342 - val_mrcnn_mask_loss: 0.2604\n",
      "Epoch 50/400\n",
      "200/200 [==============================] - 181s 904ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5545 - rpn_class_loss: 0.0099 - rpn_bbox_loss: 0.1063 - mrcnn_class_loss: 0.0900 - mrcnn_bbox_loss: 0.1089 - mrcnn_mask_loss: 0.2394 - val_loss: 0.6013 - val_rpn_class_loss: 0.0128 - val_rpn_bbox_loss: 0.1191 - val_mrcnn_class_loss: 0.0738 - val_mrcnn_bbox_loss: 0.1413 - val_mrcnn_mask_loss: 0.2544\n",
      "Epoch 51/400\n",
      "200/200 [==============================] - 181s 903ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4948 - rpn_class_loss: 0.0065 - rpn_bbox_loss: 0.0891 - mrcnn_class_loss: 0.0755 - mrcnn_bbox_loss: 0.0964 - mrcnn_mask_loss: 0.2272 - val_loss: 0.6458 - val_rpn_class_loss: 0.0125 - val_rpn_bbox_loss: 0.1531 - val_mrcnn_class_loss: 0.0894 - val_mrcnn_bbox_loss: 0.1407 - val_mrcnn_mask_loss: 0.2500\n",
      "Epoch 52/400\n",
      "200/200 [==============================] - 174s 870ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4932 - rpn_class_loss: 0.0111 - rpn_bbox_loss: 0.0920 - mrcnn_class_loss: 0.0698 - mrcnn_bbox_loss: 0.0962 - mrcnn_mask_loss: 0.2242 - val_loss: 0.5780 - val_rpn_class_loss: 0.0106 - val_rpn_bbox_loss: 0.1231 - val_mrcnn_class_loss: 0.0648 - val_mrcnn_bbox_loss: 0.1324 - val_mrcnn_mask_loss: 0.2470\n",
      "Epoch 53/400\n",
      "200/200 [==============================] - 178s 888ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5325 - rpn_class_loss: 0.0107 - rpn_bbox_loss: 0.1101 - mrcnn_class_loss: 0.0799 - mrcnn_bbox_loss: 0.1049 - mrcnn_mask_loss: 0.2269 - val_loss: 0.6252 - val_rpn_class_loss: 0.0235 - val_rpn_bbox_loss: 0.1179 - val_mrcnn_class_loss: 0.1042 - val_mrcnn_bbox_loss: 0.1388 - val_mrcnn_mask_loss: 0.2408\n",
      "Epoch 54/400\n",
      "200/200 [==============================] - 177s 886ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5054 - rpn_class_loss: 0.0095 - rpn_bbox_loss: 0.0917 - mrcnn_class_loss: 0.0830 - mrcnn_bbox_loss: 0.1000 - mrcnn_mask_loss: 0.2211 - val_loss: 0.6632 - val_rpn_class_loss: 0.0224 - val_rpn_bbox_loss: 0.1729 - val_mrcnn_class_loss: 0.0865 - val_mrcnn_bbox_loss: 0.1338 - val_mrcnn_mask_loss: 0.2475\n",
      "Epoch 55/400\n",
      "200/200 [==============================] - 173s 867ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5062 - rpn_class_loss: 0.0107 - rpn_bbox_loss: 0.0884 - mrcnn_class_loss: 0.0822 - mrcnn_bbox_loss: 0.0991 - mrcnn_mask_loss: 0.2257 - val_loss: 0.6042 - val_rpn_class_loss: 0.0084 - val_rpn_bbox_loss: 0.1505 - val_mrcnn_class_loss: 0.0530 - val_mrcnn_bbox_loss: 0.1361 - val_mrcnn_mask_loss: 0.2563\n",
      "Epoch 56/400\n",
      "200/200 [==============================] - 177s 887ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4933 - rpn_class_loss: 0.0079 - rpn_bbox_loss: 0.0967 - mrcnn_class_loss: 0.0714 - mrcnn_bbox_loss: 0.0964 - mrcnn_mask_loss: 0.2209 - val_loss: 0.6313 - val_rpn_class_loss: 0.0151 - val_rpn_bbox_loss: 0.1326 - val_mrcnn_class_loss: 0.1008 - val_mrcnn_bbox_loss: 0.1358 - val_mrcnn_mask_loss: 0.2470\n",
      "Epoch 57/400\n",
      "200/200 [==============================] - 189s 944ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5165 - rpn_class_loss: 0.0167 - rpn_bbox_loss: 0.0983 - mrcnn_class_loss: 0.0766 - mrcnn_bbox_loss: 0.0986 - mrcnn_mask_loss: 0.2263 - val_loss: 0.6983 - val_rpn_class_loss: 0.0242 - val_rpn_bbox_loss: 0.1476 - val_mrcnn_class_loss: 0.1200 - val_mrcnn_bbox_loss: 0.1464 - val_mrcnn_mask_loss: 0.2602\n",
      "Epoch 58/400\n",
      "200/200 [==============================] - 177s 884ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5009 - rpn_class_loss: 0.0114 - rpn_bbox_loss: 0.0889 - mrcnn_class_loss: 0.0842 - mrcnn_bbox_loss: 0.0956 - mrcnn_mask_loss: 0.2209 - val_loss: 0.5658 - val_rpn_class_loss: 0.0140 - val_rpn_bbox_loss: 0.1279 - val_mrcnn_class_loss: 0.0797 - val_mrcnn_bbox_loss: 0.1151 - val_mrcnn_mask_loss: 0.2291\n",
      "Epoch 59/400\n",
      "200/200 [==============================] - 176s 879ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4648 - rpn_class_loss: 0.0166 - rpn_bbox_loss: 0.0804 - mrcnn_class_loss: 0.0698 - mrcnn_bbox_loss: 0.0875 - mrcnn_mask_loss: 0.2105 - val_loss: 0.5301 - val_rpn_class_loss: 0.0083 - val_rpn_bbox_loss: 0.1112 - val_mrcnn_class_loss: 0.0693 - val_mrcnn_bbox_loss: 0.1149 - val_mrcnn_mask_loss: 0.2263\n",
      "Epoch 60/400\n",
      "200/200 [==============================] - 178s 888ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4733 - rpn_class_loss: 0.0071 - rpn_bbox_loss: 0.0869 - mrcnn_class_loss: 0.0690 - mrcnn_bbox_loss: 0.0928 - mrcnn_mask_loss: 0.2176 - val_loss: 0.5999 - val_rpn_class_loss: 0.0106 - val_rpn_bbox_loss: 0.1149 - val_mrcnn_class_loss: 0.0889 - val_mrcnn_bbox_loss: 0.1370 - val_mrcnn_mask_loss: 0.2485\n",
      "Epoch 61/400\n",
      "200/200 [==============================] - 176s 880ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4704 - rpn_class_loss: 0.0062 - rpn_bbox_loss: 0.0877 - mrcnn_class_loss: 0.0662 - mrcnn_bbox_loss: 0.0926 - mrcnn_mask_loss: 0.2178 - val_loss: 0.7982 - val_rpn_class_loss: 0.0247 - val_rpn_bbox_loss: 0.1813 - val_mrcnn_class_loss: 0.1410 - val_mrcnn_bbox_loss: 0.1709 - val_mrcnn_mask_loss: 0.2803\n",
      "Epoch 62/400\n",
      "200/200 [==============================] - 176s 879ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4381 - rpn_class_loss: 0.0077 - rpn_bbox_loss: 0.0829 - mrcnn_class_loss: 0.0532 - mrcnn_bbox_loss: 0.0835 - mrcnn_mask_loss: 0.2109 - val_loss: 0.5759 - val_rpn_class_loss: 0.0107 - val_rpn_bbox_loss: 0.1506 - val_mrcnn_class_loss: 0.0495 - val_mrcnn_bbox_loss: 0.1198 - val_mrcnn_mask_loss: 0.2454\n",
      "Epoch 63/400\n",
      "200/200 [==============================] - 177s 888ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4830 - rpn_class_loss: 0.0182 - rpn_bbox_loss: 0.0978 - mrcnn_class_loss: 0.0622 - mrcnn_bbox_loss: 0.0899 - mrcnn_mask_loss: 0.2150 - val_loss: 0.5923 - val_rpn_class_loss: 0.0185 - val_rpn_bbox_loss: 0.1434 - val_mrcnn_class_loss: 0.0715 - val_mrcnn_bbox_loss: 0.1171 - val_mrcnn_mask_loss: 0.2418\n",
      "Epoch 64/400\n",
      "200/200 [==============================] - 180s 898ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4361 - rpn_class_loss: 0.0076 - rpn_bbox_loss: 0.0827 - mrcnn_class_loss: 0.0549 - mrcnn_bbox_loss: 0.0830 - mrcnn_mask_loss: 0.2078 - val_loss: 0.7852 - val_rpn_class_loss: 0.0603 - val_rpn_bbox_loss: 0.1674 - val_mrcnn_class_loss: 0.1163 - val_mrcnn_bbox_loss: 0.1637 - val_mrcnn_mask_loss: 0.2774\n",
      "Epoch 65/400\n",
      "200/200 [==============================] - 188s 941ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4381 - rpn_class_loss: 0.0073 - rpn_bbox_loss: 0.0799 - mrcnn_class_loss: 0.0647 - mrcnn_bbox_loss: 0.0818 - mrcnn_mask_loss: 0.2043 - val_loss: 0.5790 - val_rpn_class_loss: 0.0196 - val_rpn_bbox_loss: 0.1145 - val_mrcnn_class_loss: 0.0820 - val_mrcnn_bbox_loss: 0.1246 - val_mrcnn_mask_loss: 0.2383\n",
      "Epoch 66/400\n",
      "104/200 [==============>...............] - ETA: 1:13 - batch: 51.5000 - size: 1.0000 - loss: 0.4709 - rpn_class_loss: 0.0186 - rpn_bbox_loss: 0.0895 - mrcnn_class_loss: 0.0652 - mrcnn_bbox_loss: 0.0873 - mrcnn_mask_loss: 0.2102"
     ]
    }
   ],
   "source": [
    "# Create model in training mode\n",
    "# model = modellib.MaskRCNN(mode=\"training\", config=opt,\n",
    "#                           model_dir=opt.MODEL_DIR)\n",
    "config = BalloonConfig()\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=DEFAULT_LOGS_DIR)\n",
    "\n",
    "# Which weights to start with?\n",
    "init_with = config.INIT_IT  # imagenet, coco, or last\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    if not os.path.exists(opt.COCO_MODEL_PATH):\n",
    "        utils.download_trained_weights(opt.COCO_MODEL_PATH)\n",
    "    \n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(opt.COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Looking for the latest model to continue training. If this is not\n",
    "    # what you want provide the path to the model you wish to resume training on\n",
    "\n",
    "    # by kiprono@aims.ac.za\n",
    "    from pathlib import Path\n",
    "    latest_model_dir = sorted(Path(DEFAULT_LOGS_DIR).iterdir(),\\\n",
    "                            key=os.path.getmtime)[-1]\n",
    "    latest_model_file = sorted([i for i in Path(latest_model_dir).iterdir()\\\n",
    "            if str(i).endswith('.h5')], key=os.path.getmtime)[-1]\n",
    "\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(latest_model_file, by_name=True)\n",
    "    \n",
    "'''\n",
    "train\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers \n",
    "    (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, \n",
    "    pass layers='heads' to the train() function.\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. \n",
    "    Simply pass layers=\"all to train all layers.\n",
    "'''\n",
    "\n",
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "\n",
    "# Fine tuning \"all\" layers\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=400, \n",
    "            layers='all')\n",
    "\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=config.LEARNING_RATE,\n",
    "#             epochs=80,\n",
    "#             layers='all')\n",
    "\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=config.LEARNING_RATE/10,\n",
    "#             epochs=120,\n",
    "#             layers='all')\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=config.LEARNING_RATE/20,\n",
    "#             epochs=200,\n",
    "#             layers='all')\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=config.LEARNING_RATE/30,\n",
    "#             epochs=280,\n",
    "#             layers='all')\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=config.LEARNING_RATE/30,\n",
    "#             epochs=360,\n",
    "#             layers='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vH5y6H3BX8-M"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPrRT9j9wFG/TSJPmZds89F",
   "collapsed_sections": [],
   "name": "fruits_train_TF2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
