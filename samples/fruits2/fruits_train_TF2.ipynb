{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26972,
     "status": "ok",
     "timestamp": 1624772187306,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "vSfZS4V-HJXi",
    "outputId": "7f97cbfc-7c1b-4fa0-8047-7e289e179fe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive,files\n",
    "drive.mount(\"/content/gdrive\", force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1624753210549,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "u6QqHvLIH1QV"
   },
   "outputs": [],
   "source": [
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1624772188787,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "MnOPm0FLH1S3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/gdrive/My Drive/2/Mask_RCNN_TF2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1624772188789,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "ZbhoPojrIOn6"
   },
   "outputs": [],
   "source": [
    "# !pip install --quiet --upgrade -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1681,
     "status": "ok",
     "timestamp": 1624772190464,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "ocp09V7OINoX",
    "outputId": "d22e59c3-fe57-4fef-9240-f84377045cd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "# import keras\n",
    "# print(keras.__version__)\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1624772194077,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "cBzfMt83OI0r",
    "outputId": "dc231564-ed65-491e-f236-a482a9802f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2156,
     "status": "ok",
     "timestamp": 1624772197522,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "5xXOjRInH88_"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./mrcnn\")  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1624772198464,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "fCd4n74DJR2k"
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = './'\n",
    "DATA_DIR = './datasets/fruits2'\n",
    "DEFAULT_LOGS_DIR = './assets/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20809,
     "status": "ok",
     "timestamp": 1624772220367,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "tAkd1wHAa-PI",
    "outputId": "5d1023f5-83c1-4403-ec3a-49dae7ce0a5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(os.path.join(DATA_DIR, \"train-images\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1624772220369,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "gQfhB-1PH1Vc",
    "outputId": "1145a154-1112-459b-8e4f-8fb1577b7c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO weights already exists\n"
     ]
    }
   ],
   "source": [
    "# Local path to trained weights file\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_WEIGHTS_PATH):\n",
    "    utils.download_trained_weights(COCO_WEIGHTS_PATH)\n",
    "else:\n",
    "    print(\"COCO weights already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1624772220370,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "l7KCwhUEH1YB"
   },
   "outputs": [],
   "source": [
    "class BalloonConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"fruits2-\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU =   1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + baloon\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 200\n",
    "\n",
    "    # Skip detections with the following confidence level\n",
    "    DETECTION_MIN_CONFIDENCE = 0.90\n",
    "\n",
    "    # Initial weights\n",
    "    # INIT_IT = \"imagenet\"\n",
    "    INIT_IT = \"last\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1624772224167,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "slcI2pfBH1aJ"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "#  Dataset\n",
    "############################################################\n",
    "\n",
    "class BalloonDataset(utils.Dataset):\n",
    "\n",
    "    def load_balloon(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the Balloon dataset.\n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "        # Add classes. We have only one class to add.\n",
    "        self.add_class(\"balloon\", 1, \"balloon\")\n",
    "\n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"train-images\", \"val-images\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        # Load annotations\n",
    "        # VGG Image Annotator saves each image in the form:\n",
    "        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n",
    "        #   'regions': {\n",
    "        #       '0': {\n",
    "        #           'region_attributes': {},\n",
    "        #           'shape_attributes': {\n",
    "        #               'all_points_x': [...],\n",
    "        #               'all_points_y': [...],\n",
    "        #               'name': 'polygon'}},\n",
    "        #       ... more regions ...\n",
    "        #   },\n",
    "        #   'size': 100202\n",
    "        # }\n",
    "\n",
    "        # We mostly care about the x and y coordinates of each region\n",
    "        annotations = json.load(open(os.path.join(dataset_dir, \"via_project_fruits.json\")))\n",
    "        annotations = list(annotations.values())  # don't need the dict keys\n",
    "\n",
    "        # The VIA tool saves images in the JSON even if they don't have any\n",
    "        # annotations. Skip unannotated images.\n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "        # Add images\n",
    "        for a in annotations:\n",
    "            # Get the x, y coordinaets of points of the polygons that make up\n",
    "            # the outline of each object instance. There are stores in the\n",
    "            # shape_attributes (see json format above)\n",
    "            polygons = [r['shape_attributes'] for r in a['regions']]\n",
    "            # load_mask() needs the image size to convert polygons to masks.\n",
    "            # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
    "            # the image. This is only managable since the dataset is tiny.\n",
    "\n",
    "            image_path = os.path.join(dataset_dir, a['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "            \n",
    "            self.add_image(\n",
    "                \"balloon\",\n",
    "                image_id=a['filename'],  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                polygons=polygons)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"\n",
    "        Generate instance masks for an image.\n",
    "        Returns:\n",
    "            masks: A bool array of shape [height, width, instance count] with\n",
    "                one mask per instance.\n",
    "            class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a balloon dataset image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"balloon\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        return mask, np.ones([mask.shape[-1]], dtype=np.float32) #dtype=np.int32\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"balloon\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 574992,
     "status": "ok",
     "timestamp": 1624772801310,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivgYnoX6t6S8yiUl8wsgdetGvseuAZ9OkTv1XPC1A=s64",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "Z2aKWNIcH1cf"
   },
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = BalloonDataset()\n",
    "dataset_train.load_balloon(DATA_DIR, \"train-images\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = BalloonDataset()\n",
    "dataset_val.load_balloon(DATA_DIR, \"val-images\")\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cRtPMczKXvi",
    "outputId": "6f759c1d-ea0e-4d0a-e85d-a07d6a6e4f25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Re-starting from epoch 40\n",
      "\n",
      "Starting at epoch 40. LR=0.001\n",
      "\n",
      "Checkpoint Path: ./assets/logs/fruits2-20210627T0034/mask_rcnn_fruits2-_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (ConstLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 41/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_2:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_5:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_8:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_11:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - ETA: 0s - batch: 99.5000 - size: 1.0000 - loss: 0.6182 - rpn_class_loss: 0.0152 - rpn_bbox_loss: 0.1186 - mrcnn_class_loss: 0.1134 - mrcnn_bbox_loss: 0.1263 - mrcnn_mask_loss: 0.2447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 278s 1s/step - batch: 99.5000 - size: 1.0000 - loss: 0.6182 - rpn_class_loss: 0.0152 - rpn_bbox_loss: 0.1186 - mrcnn_class_loss: 0.1134 - mrcnn_bbox_loss: 0.1263 - mrcnn_mask_loss: 0.2447 - val_loss: 0.8264 - val_rpn_class_loss: 0.0477 - val_rpn_bbox_loss: 0.2836 - val_mrcnn_class_loss: 0.0937 - val_mrcnn_bbox_loss: 0.1424 - val_mrcnn_mask_loss: 0.2591\n",
      "Epoch 42/400\n",
      "200/200 [==============================] - 176s 879ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5686 - rpn_class_loss: 0.0122 - rpn_bbox_loss: 0.1161 - mrcnn_class_loss: 0.0852 - mrcnn_bbox_loss: 0.1142 - mrcnn_mask_loss: 0.2409 - val_loss: 0.6506 - val_rpn_class_loss: 0.0166 - val_rpn_bbox_loss: 0.1289 - val_mrcnn_class_loss: 0.1086 - val_mrcnn_bbox_loss: 0.1427 - val_mrcnn_mask_loss: 0.2537\n",
      "Epoch 43/400\n",
      "200/200 [==============================] - 176s 878ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.6227 - rpn_class_loss: 0.0218 - rpn_bbox_loss: 0.1258 - mrcnn_class_loss: 0.0977 - mrcnn_bbox_loss: 0.1269 - mrcnn_mask_loss: 0.2504 - val_loss: 0.6853 - val_rpn_class_loss: 0.0164 - val_rpn_bbox_loss: 0.1989 - val_mrcnn_class_loss: 0.0808 - val_mrcnn_bbox_loss: 0.1338 - val_mrcnn_mask_loss: 0.2554\n",
      "Epoch 44/400\n",
      "200/200 [==============================] - 176s 878ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5687 - rpn_class_loss: 0.0115 - rpn_bbox_loss: 0.1142 - mrcnn_class_loss: 0.0904 - mrcnn_bbox_loss: 0.1167 - mrcnn_mask_loss: 0.2359 - val_loss: 0.6402 - val_rpn_class_loss: 0.0102 - val_rpn_bbox_loss: 0.1282 - val_mrcnn_class_loss: 0.0851 - val_mrcnn_bbox_loss: 0.1474 - val_mrcnn_mask_loss: 0.2692\n",
      "Epoch 45/400\n",
      "200/200 [==============================] - 176s 880ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5674 - rpn_class_loss: 0.0101 - rpn_bbox_loss: 0.1111 - mrcnn_class_loss: 0.0864 - mrcnn_bbox_loss: 0.1172 - mrcnn_mask_loss: 0.2426 - val_loss: 0.6446 - val_rpn_class_loss: 0.0115 - val_rpn_bbox_loss: 0.1529 - val_mrcnn_class_loss: 0.0857 - val_mrcnn_bbox_loss: 0.1468 - val_mrcnn_mask_loss: 0.2476\n",
      "Epoch 46/400\n",
      "200/200 [==============================] - 175s 875ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5752 - rpn_class_loss: 0.0131 - rpn_bbox_loss: 0.1081 - mrcnn_class_loss: 0.0984 - mrcnn_bbox_loss: 0.1176 - mrcnn_mask_loss: 0.2380 - val_loss: 0.6197 - val_rpn_class_loss: 0.0120 - val_rpn_bbox_loss: 0.1279 - val_mrcnn_class_loss: 0.0923 - val_mrcnn_bbox_loss: 0.1370 - val_mrcnn_mask_loss: 0.2505\n",
      "Epoch 47/400\n",
      "200/200 [==============================] - 175s 875ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5778 - rpn_class_loss: 0.0209 - rpn_bbox_loss: 0.1140 - mrcnn_class_loss: 0.0892 - mrcnn_bbox_loss: 0.1149 - mrcnn_mask_loss: 0.2388 - val_loss: 0.6051 - val_rpn_class_loss: 0.0102 - val_rpn_bbox_loss: 0.1274 - val_mrcnn_class_loss: 0.0837 - val_mrcnn_bbox_loss: 0.1339 - val_mrcnn_mask_loss: 0.2499\n",
      "Epoch 48/400\n",
      "200/200 [==============================] - 176s 882ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5491 - rpn_class_loss: 0.0112 - rpn_bbox_loss: 0.1098 - mrcnn_class_loss: 0.0918 - mrcnn_bbox_loss: 0.1074 - mrcnn_mask_loss: 0.2290 - val_loss: 0.7140 - val_rpn_class_loss: 0.0165 - val_rpn_bbox_loss: 0.1871 - val_mrcnn_class_loss: 0.1041 - val_mrcnn_bbox_loss: 0.1400 - val_mrcnn_mask_loss: 0.2662\n",
      "Epoch 49/400\n",
      "200/200 [==============================] - 177s 885ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5432 - rpn_class_loss: 0.0126 - rpn_bbox_loss: 0.1025 - mrcnn_class_loss: 0.0910 - mrcnn_bbox_loss: 0.1070 - mrcnn_mask_loss: 0.2301 - val_loss: 0.5866 - val_rpn_class_loss: 0.0088 - val_rpn_bbox_loss: 0.1367 - val_mrcnn_class_loss: 0.0558 - val_mrcnn_bbox_loss: 0.1319 - val_mrcnn_mask_loss: 0.2534\n",
      "Epoch 50/400\n",
      "200/200 [==============================] - 177s 884ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5828 - rpn_class_loss: 0.0146 - rpn_bbox_loss: 0.1203 - mrcnn_class_loss: 0.0905 - mrcnn_bbox_loss: 0.1178 - mrcnn_mask_loss: 0.2395 - val_loss: 0.6858 - val_rpn_class_loss: 0.0183 - val_rpn_bbox_loss: 0.1470 - val_mrcnn_class_loss: 0.0956 - val_mrcnn_bbox_loss: 0.1556 - val_mrcnn_mask_loss: 0.2694\n",
      "Epoch 51/400\n",
      "200/200 [==============================] - 176s 880ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5082 - rpn_class_loss: 0.0109 - rpn_bbox_loss: 0.0961 - mrcnn_class_loss: 0.0758 - mrcnn_bbox_loss: 0.1030 - mrcnn_mask_loss: 0.2225 - val_loss: 0.6245 - val_rpn_class_loss: 0.0115 - val_rpn_bbox_loss: 0.1245 - val_mrcnn_class_loss: 0.0808 - val_mrcnn_bbox_loss: 0.1391 - val_mrcnn_mask_loss: 0.2685\n",
      "Epoch 52/400\n",
      "200/200 [==============================] - 177s 883ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5539 - rpn_class_loss: 0.0117 - rpn_bbox_loss: 0.1064 - mrcnn_class_loss: 0.0917 - mrcnn_bbox_loss: 0.1094 - mrcnn_mask_loss: 0.2347 - val_loss: 0.7611 - val_rpn_class_loss: 0.0282 - val_rpn_bbox_loss: 0.2145 - val_mrcnn_class_loss: 0.0844 - val_mrcnn_bbox_loss: 0.1569 - val_mrcnn_mask_loss: 0.2770\n",
      "Epoch 53/400\n",
      "200/200 [==============================] - 176s 882ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5035 - rpn_class_loss: 0.0076 - rpn_bbox_loss: 0.0978 - mrcnn_class_loss: 0.0669 - mrcnn_bbox_loss: 0.1036 - mrcnn_mask_loss: 0.2276 - val_loss: 0.6551 - val_rpn_class_loss: 0.0204 - val_rpn_bbox_loss: 0.1605 - val_mrcnn_class_loss: 0.0848 - val_mrcnn_bbox_loss: 0.1362 - val_mrcnn_mask_loss: 0.2533\n",
      "Epoch 54/400\n",
      "200/200 [==============================] - 178s 888ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5400 - rpn_class_loss: 0.0101 - rpn_bbox_loss: 0.1012 - mrcnn_class_loss: 0.0885 - mrcnn_bbox_loss: 0.1065 - mrcnn_mask_loss: 0.2337 - val_loss: 0.6738 - val_rpn_class_loss: 0.0346 - val_rpn_bbox_loss: 0.1412 - val_mrcnn_class_loss: 0.1047 - val_mrcnn_bbox_loss: 0.1429 - val_mrcnn_mask_loss: 0.2504\n",
      "Epoch 55/400\n",
      "200/200 [==============================] - 178s 891ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5352 - rpn_class_loss: 0.0080 - rpn_bbox_loss: 0.1054 - mrcnn_class_loss: 0.0799 - mrcnn_bbox_loss: 0.1083 - mrcnn_mask_loss: 0.2337 - val_loss: 0.7562 - val_rpn_class_loss: 0.0258 - val_rpn_bbox_loss: 0.1905 - val_mrcnn_class_loss: 0.1187 - val_mrcnn_bbox_loss: 0.1513 - val_mrcnn_mask_loss: 0.2700\n",
      "Epoch 56/400\n",
      "200/200 [==============================] - 176s 878ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5210 - rpn_class_loss: 0.0107 - rpn_bbox_loss: 0.1026 - mrcnn_class_loss: 0.0757 - mrcnn_bbox_loss: 0.1038 - mrcnn_mask_loss: 0.2282 - val_loss: 0.6068 - val_rpn_class_loss: 0.0115 - val_rpn_bbox_loss: 0.1222 - val_mrcnn_class_loss: 0.0825 - val_mrcnn_bbox_loss: 0.1363 - val_mrcnn_mask_loss: 0.2543\n",
      "Epoch 57/400\n",
      "200/200 [==============================] - 177s 885ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5386 - rpn_class_loss: 0.0113 - rpn_bbox_loss: 0.1017 - mrcnn_class_loss: 0.0900 - mrcnn_bbox_loss: 0.1042 - mrcnn_mask_loss: 0.2314 - val_loss: 0.6305 - val_rpn_class_loss: 0.0114 - val_rpn_bbox_loss: 0.1555 - val_mrcnn_class_loss: 0.0671 - val_mrcnn_bbox_loss: 0.1384 - val_mrcnn_mask_loss: 0.2581\n",
      "Epoch 58/400\n",
      "200/200 [==============================] - 178s 889ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5131 - rpn_class_loss: 0.0107 - rpn_bbox_loss: 0.0986 - mrcnn_class_loss: 0.0743 - mrcnn_bbox_loss: 0.1019 - mrcnn_mask_loss: 0.2275 - val_loss: 0.6848 - val_rpn_class_loss: 0.0188 - val_rpn_bbox_loss: 0.1669 - val_mrcnn_class_loss: 0.1026 - val_mrcnn_bbox_loss: 0.1375 - val_mrcnn_mask_loss: 0.2590\n",
      "Epoch 59/400\n",
      "200/200 [==============================] - 177s 885ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5142 - rpn_class_loss: 0.0110 - rpn_bbox_loss: 0.1009 - mrcnn_class_loss: 0.0759 - mrcnn_bbox_loss: 0.1016 - mrcnn_mask_loss: 0.2249 - val_loss: 0.5781 - val_rpn_class_loss: 0.0130 - val_rpn_bbox_loss: 0.1102 - val_mrcnn_class_loss: 0.0784 - val_mrcnn_bbox_loss: 0.1253 - val_mrcnn_mask_loss: 0.2511\n",
      "Epoch 60/400\n",
      "200/200 [==============================] - 179s 894ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4710 - rpn_class_loss: 0.0077 - rpn_bbox_loss: 0.0832 - mrcnn_class_loss: 0.0694 - mrcnn_bbox_loss: 0.0929 - mrcnn_mask_loss: 0.2177 - val_loss: 0.6077 - val_rpn_class_loss: 0.0263 - val_rpn_bbox_loss: 0.1443 - val_mrcnn_class_loss: 0.0656 - val_mrcnn_bbox_loss: 0.1258 - val_mrcnn_mask_loss: 0.2458\n",
      "Epoch 61/400\n",
      "200/200 [==============================] - 178s 892ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4733 - rpn_class_loss: 0.0084 - rpn_bbox_loss: 0.0861 - mrcnn_class_loss: 0.0727 - mrcnn_bbox_loss: 0.0913 - mrcnn_mask_loss: 0.2149 - val_loss: 0.6471 - val_rpn_class_loss: 0.0124 - val_rpn_bbox_loss: 0.1716 - val_mrcnn_class_loss: 0.0736 - val_mrcnn_bbox_loss: 0.1351 - val_mrcnn_mask_loss: 0.2544\n",
      "Epoch 62/400\n",
      "200/200 [==============================] - 179s 894ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4884 - rpn_class_loss: 0.0080 - rpn_bbox_loss: 0.0912 - mrcnn_class_loss: 0.0756 - mrcnn_bbox_loss: 0.0944 - mrcnn_mask_loss: 0.2192 - val_loss: 0.5973 - val_rpn_class_loss: 0.0176 - val_rpn_bbox_loss: 0.1369 - val_mrcnn_class_loss: 0.0849 - val_mrcnn_bbox_loss: 0.1158 - val_mrcnn_mask_loss: 0.2420\n",
      "Epoch 63/400\n",
      "200/200 [==============================] - 179s 893ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4914 - rpn_class_loss: 0.0088 - rpn_bbox_loss: 0.0908 - mrcnn_class_loss: 0.0693 - mrcnn_bbox_loss: 0.0983 - mrcnn_mask_loss: 0.2243 - val_loss: 0.5423 - val_rpn_class_loss: 0.0147 - val_rpn_bbox_loss: 0.1267 - val_mrcnn_class_loss: 0.0646 - val_mrcnn_bbox_loss: 0.1058 - val_mrcnn_mask_loss: 0.2305\n",
      "Epoch 64/400\n",
      "200/200 [==============================] - 180s 899ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5010 - rpn_class_loss: 0.0094 - rpn_bbox_loss: 0.0961 - mrcnn_class_loss: 0.0717 - mrcnn_bbox_loss: 0.0997 - mrcnn_mask_loss: 0.2241 - val_loss: 0.7137 - val_rpn_class_loss: 0.0620 - val_rpn_bbox_loss: 0.1871 - val_mrcnn_class_loss: 0.0835 - val_mrcnn_bbox_loss: 0.1386 - val_mrcnn_mask_loss: 0.2425\n",
      "Epoch 65/400\n",
      "200/200 [==============================] - 181s 904ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4935 - rpn_class_loss: 0.0104 - rpn_bbox_loss: 0.0973 - mrcnn_class_loss: 0.0703 - mrcnn_bbox_loss: 0.0960 - mrcnn_mask_loss: 0.2195 - val_loss: 0.5692 - val_rpn_class_loss: 0.0097 - val_rpn_bbox_loss: 0.1118 - val_mrcnn_class_loss: 0.0875 - val_mrcnn_bbox_loss: 0.1246 - val_mrcnn_mask_loss: 0.2356\n",
      "Epoch 66/400\n",
      "200/200 [==============================] - 179s 894ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.5020 - rpn_class_loss: 0.0193 - rpn_bbox_loss: 0.0956 - mrcnn_class_loss: 0.0745 - mrcnn_bbox_loss: 0.0938 - mrcnn_mask_loss: 0.2188 - val_loss: 0.6824 - val_rpn_class_loss: 0.0272 - val_rpn_bbox_loss: 0.1659 - val_mrcnn_class_loss: 0.1021 - val_mrcnn_bbox_loss: 0.1388 - val_mrcnn_mask_loss: 0.2483\n",
      "Epoch 67/400\n",
      "200/200 [==============================] - 179s 894ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4560 - rpn_class_loss: 0.0080 - rpn_bbox_loss: 0.0864 - mrcnn_class_loss: 0.0628 - mrcnn_bbox_loss: 0.0888 - mrcnn_mask_loss: 0.2100 - val_loss: 0.6166 - val_rpn_class_loss: 0.0212 - val_rpn_bbox_loss: 0.1490 - val_mrcnn_class_loss: 0.0777 - val_mrcnn_bbox_loss: 0.1235 - val_mrcnn_mask_loss: 0.2451\n",
      "Epoch 68/400\n",
      "200/200 [==============================] - 178s 891ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4783 - rpn_class_loss: 0.0088 - rpn_bbox_loss: 0.0924 - mrcnn_class_loss: 0.0705 - mrcnn_bbox_loss: 0.0911 - mrcnn_mask_loss: 0.2155 - val_loss: 0.5158 - val_rpn_class_loss: 0.0093 - val_rpn_bbox_loss: 0.0973 - val_mrcnn_class_loss: 0.0789 - val_mrcnn_bbox_loss: 0.1106 - val_mrcnn_mask_loss: 0.2197\n",
      "Epoch 69/400\n",
      "200/200 [==============================] - 180s 899ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4705 - rpn_class_loss: 0.0123 - rpn_bbox_loss: 0.0866 - mrcnn_class_loss: 0.0666 - mrcnn_bbox_loss: 0.0915 - mrcnn_mask_loss: 0.2135 - val_loss: 0.6717 - val_rpn_class_loss: 0.0739 - val_rpn_bbox_loss: 0.1793 - val_mrcnn_class_loss: 0.0674 - val_mrcnn_bbox_loss: 0.1155 - val_mrcnn_mask_loss: 0.2355\n",
      "Epoch 70/400\n",
      "200/200 [==============================] - 180s 901ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4443 - rpn_class_loss: 0.0060 - rpn_bbox_loss: 0.0826 - mrcnn_class_loss: 0.0618 - mrcnn_bbox_loss: 0.0861 - mrcnn_mask_loss: 0.2078 - val_loss: 0.6727 - val_rpn_class_loss: 0.0544 - val_rpn_bbox_loss: 0.1588 - val_mrcnn_class_loss: 0.0912 - val_mrcnn_bbox_loss: 0.1274 - val_mrcnn_mask_loss: 0.2409\n",
      "Epoch 71/400\n",
      "200/200 [==============================] - 178s 891ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4362 - rpn_class_loss: 0.0060 - rpn_bbox_loss: 0.0781 - mrcnn_class_loss: 0.0614 - mrcnn_bbox_loss: 0.0838 - mrcnn_mask_loss: 0.2068 - val_loss: 0.6620 - val_rpn_class_loss: 0.0156 - val_rpn_bbox_loss: 0.1522 - val_mrcnn_class_loss: 0.0739 - val_mrcnn_bbox_loss: 0.1474 - val_mrcnn_mask_loss: 0.2729\n",
      "Epoch 72/400\n",
      "200/200 [==============================] - 181s 905ms/step - batch: 99.5000 - size: 1.0000 - loss: 0.4180 - rpn_class_loss: 0.0051 - rpn_bbox_loss: 0.0789 - mrcnn_class_loss: 0.0476 - mrcnn_bbox_loss: 0.0813 - mrcnn_mask_loss: 0.2051 - val_loss: 0.7297 - val_rpn_class_loss: 0.0229 - val_rpn_bbox_loss: 0.1576 - val_mrcnn_class_loss: 0.1274 - val_mrcnn_bbox_loss: 0.1526 - val_mrcnn_mask_loss: 0.2693\n",
      "Epoch 73/400\n",
      "117/200 [================>.............] - ETA: 1:04 - batch: 58.0000 - size: 1.0000 - loss: 0.4672 - rpn_class_loss: 0.0072 - rpn_bbox_loss: 0.0892 - mrcnn_class_loss: 0.0581 - mrcnn_bbox_loss: 0.0905 - mrcnn_mask_loss: 0.2222"
     ]
    }
   ],
   "source": [
    "# Create model in training mode\n",
    "# model = modellib.MaskRCNN(mode=\"training\", config=opt,\n",
    "#                           model_dir=opt.MODEL_DIR)\n",
    "config = BalloonConfig()\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=DEFAULT_LOGS_DIR)\n",
    "\n",
    "# Which weights to start with?\n",
    "init_with = config.INIT_IT  # imagenet, coco, or last\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    if not os.path.exists(opt.COCO_MODEL_PATH):\n",
    "        utils.download_trained_weights(opt.COCO_MODEL_PATH)\n",
    "    \n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(opt.COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    last_weight_path = \\\n",
    "    os.path.join(os.getcwd(),\"assets/logs/fruits2-20210627T0034/mask_rcnn_fruits2-_0040.h5\")\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(last_weight_path, by_name=True)\n",
    "    \n",
    "\n",
    "'''\n",
    "train\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers \n",
    "    (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, \n",
    "    pass layers='heads' to the train() function.\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. \n",
    "    Simply pass layers=\"all to train all layers.\n",
    "'''\n",
    "\n",
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "\n",
    "# Fine tuning \"all\" layers\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=400, \n",
    "            layers='all')\n",
    "\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=config.LEARNING_RATE,\n",
    "#             epochs=80,\n",
    "#             layers='all')\n",
    "\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=config.LEARNING_RATE/10,\n",
    "#             epochs=120,\n",
    "#             layers='all')\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=config.LEARNING_RATE/20,\n",
    "#             epochs=200,\n",
    "#             layers='all')\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=config.LEARNING_RATE/30,\n",
    "#             epochs=280,\n",
    "#             layers='all')\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=config.LEARNING_RATE/30,\n",
    "#             epochs=360,\n",
    "#             layers='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vH5y6H3BX8-M"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMolqw8ZHXNfjVg8uDVNwln",
   "collapsed_sections": [],
   "name": "fruits_train_TF2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
