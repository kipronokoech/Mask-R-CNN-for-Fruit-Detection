{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1307,
     "status": "ok",
     "timestamp": 1622013951795,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh5.googleusercontent.com/-1cfglh_j7Tw/AAAAAAAAAAI/AAAAAAAAQL0/uT7Ehc7X2bI/s64/photo.jpg",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "BlhyRs7g_uW2",
    "outputId": "b754b57f-2ed2-4c1a-fb79-ee3708d4e375"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive,files\n",
    "# drive.mount(\"/content/gdrive\", force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kXaY3oee3P8W"
   },
   "outputs": [],
   "source": [
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Hr57LG0UB8Np"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.stdout = open('/content/gdrive/My Drive/2/Mask_RCNN/output_logs', 'w')\n",
    "# print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4373,
     "status": "ok",
     "timestamp": 1621687507678,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh5.googleusercontent.com/-1cfglh_j7Tw/AAAAAAAAAAI/AAAAAAAAQL0/uT7Ehc7X2bI/s64/photo.jpg",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "yH4MuBo03Rq8",
    "outputId": "f639089d-06bb-4476-93ea-3426b8cc66e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiprono/.local/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.4\n",
      "2.2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "# %tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "# !pip install -q keras==2.2.5\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ifer8bJeL84p"
   },
   "source": [
    "# BUILDING THE MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uAtlV6Dz4YkM"
   },
   "outputs": [],
   "source": [
    "os.chdir('../')\n",
    "ROOT_DIR = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "f2TI-YcX4SIj"
   },
   "outputs": [],
   "source": [
    "SAMPLES_DIR = './assets/datasets/fruits2'\n",
    "\n",
    "DATA_DIR = './assets/datasets/fruits2'\n",
    "\n",
    "# Directory to save logs and trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mlueugLP4_wm"
   },
   "outputs": [],
   "source": [
    "#!git clone https://www.github.com/matterport/Mask_RCNN.git ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1HIfebEU5Bj3"
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"./mrcnn\")  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sgmbZsil5Bm6"
   },
   "outputs": [],
   "source": [
    "#!wget --quiet https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
    " #!ls -lh mask_rcnn_coco.h5\n",
    "\n",
    "COCO_WEIGHTS_PATH = \"./mask_rcnn_coco.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bI6ycYDu5Bpd"
   },
   "outputs": [],
   "source": [
    "DEFAULT_LOGS_DIR = './assets/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EurGKLXE5Bu3"
   },
   "outputs": [],
   "source": [
    "class BalloonConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"fruits2\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU =   1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + baloon\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 200\n",
    "\n",
    "    # Skip detections with the following confidence level\n",
    "    DETECTION_MIN_CONFIDENCE = 0.90\n",
    "\n",
    "    # Initial weights\n",
    "    # INIT_IT = \"imagenet\"\n",
    "    INIT_IT = \"imagenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ft1mNEKC5Bxl"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "#  Dataset\n",
    "############################################################\n",
    "\n",
    "class BalloonDataset(utils.Dataset):\n",
    "\n",
    "    def load_balloon(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the Balloon dataset.\n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "        # Add classes. We have only one class to add.\n",
    "        self.add_class(\"balloon\", 1, \"balloon\")\n",
    "\n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"train\", \"val\"],\"subset can only be train or val\"\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        # Load annotations\n",
    "        # VGG Image Annotator saves each image in the form:\n",
    "        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n",
    "        #   'regions': {\n",
    "        #       '0': {\n",
    "        #           'region_attributes': {},\n",
    "        #           'shape_attributes': {\n",
    "        #               'all_points_x': [...],\n",
    "        #               'all_points_y': [...],\n",
    "        #               'name': 'polygon'}},\n",
    "        #       ... more regions ...\n",
    "        #   },\n",
    "        #   'size': 100202\n",
    "        # }\n",
    "\n",
    "        # We mostly care about the x and y coordinates of each region\n",
    "        annotations = json.load(open(os.path.join(dataset_dir, \"via_project_fruits2.json\")))\n",
    "        annotations = list(annotations.values())  # don't need the dict keys\n",
    "\n",
    "        # The VIA tool saves images in the JSON even if they don't have any\n",
    "        # annotations. Skip unannotated images.\n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "        # Add images\n",
    "        for a in annotations:\n",
    "            # Get the x, y coordinaets of points of the polygons that make up\n",
    "            # the outline of each object instance. There are stores in the\n",
    "            # shape_attributes (see json format above)\n",
    "            polygons = [r['shape_attributes'] for r in a['regions']]\n",
    "            # load_mask() needs the image size to convert polygons to masks.\n",
    "            # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
    "            # the image. This is only managable since the dataset is tiny.\n",
    "            image_path = os.path.join(dataset_dir, a['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            self.add_image(\n",
    "                \"balloon\",\n",
    "                image_id=a['filename'],  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                polygons=polygons)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"\n",
    "        Generate instance masks for an image.\n",
    "        Returns:\n",
    "            masks: A bool array of shape [height, width, instance count] with\n",
    "                one mask per instance.\n",
    "            class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a balloon dataset image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"balloon\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        return mask, np.ones([mask.shape[-1]], dtype=np.float32) #dtype=np.int32\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"balloon\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qafUccnPy6wn"
   },
   "source": [
    "## TRAINING - Code testing part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "executionInfo": {
     "elapsed": 31843,
     "status": "ok",
     "timestamp": 1621687540703,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh5.googleusercontent.com/-1cfglh_j7Tw/AAAAAAAAAAI/AAAAAAAAQL0/uT7Ehc7X2bI/s64/photo.jpg",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "iVv9EY8dy2iC",
    "outputId": "36e3c9be-0564-4166-98f5-20a641f6ea5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Load and display random samples\\nimage_ids = np.random.choice(dataset_train.image_ids, 4)\\nfor image_id in image_ids:\\n    image = dataset_train.load_image(image_id)\\n    mask, class_ids = dataset_train.load_mask(image_id)\\n    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\\n '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ['KERAS_BACKEND']='tensorflow'\n",
    "# import sys\n",
    "# sys.path.append('../')\n",
    "\n",
    "# from config2 import *\n",
    "# from dataset import NucleiDataset\n",
    "# import numpy as np\n",
    "# import model as modellib\n",
    "# from model import log\n",
    "# import utils\n",
    "# import random\n",
    "\n",
    "sys.path.append(\"./mrcnn\")  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "# Training dataset\n",
    "# dataset_train = NucleiDataset()\n",
    "# dataset_train.add_nuclei(opt.train_data_root,'train')\n",
    "# dataset_train.prepare()\n",
    "\n",
    "dataset_train = BalloonDataset()\n",
    "dataset_train.load_balloon(SAMPLES_DIR, \"train\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "# dataset_val = NucleiDataset()\n",
    "# dataset_val.add_nuclei(opt.val_data_root,'val')\n",
    "# dataset_val.prepare()\n",
    "\n",
    "dataset_val = BalloonDataset()\n",
    "dataset_val.load_balloon(SAMPLES_DIR, \"val\")\n",
    "dataset_val.prepare()\n",
    "\n",
    "\"\"\"\n",
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    " \"\"\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RW4EpwHZFhcz",
    "outputId": "bbbd382d-aa9f-43f7-affd-6c5c382734fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kiprono/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiprono/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiprono/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiprono/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiprono/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiprono/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: ./assets/logs/fruits220210914T1631/mask_rcnn_fruits2_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kiprono/.local/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiprono/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/kiprono/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/kiprono/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kiprono/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiprono/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiprono/.local/lib/python3.7/site-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kiprono/.local/lib/python3.7/site-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiprono/.local/lib/python3.7/site-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/40\n",
      "  2/200 [..............................] - ETA: 2:46:52 - loss: 4.8277 - rpn_class_loss: 1.6129 - rpn_bbox_loss: 2.3318 - mrcnn_class_loss: 0.8829 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "# Create model in training mode\n",
    "# model = modellib.MaskRCNN(mode=\"training\", config=opt,\n",
    "#                           model_dir=opt.MODEL_DIR)\n",
    "config = BalloonConfig()\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=DEFAULT_LOGS_DIR)\n",
    "\n",
    "# Which weights to start with?\n",
    "init_with = config.INIT_IT  # imagenet, coco, or last\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    if not os.path.exists(opt.COCO_MODEL_PATH):\n",
    "        utils.download_trained_weights(opt.COCO_MODEL_PATH)\n",
    "    \n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(opt.COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    last_weight_path = \\\n",
    "    os.path.join(os.getcwd(),\"assets/logs/fruits220210518T1629/mask_rcnn_fruits2_0141.h5\")\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(last_weight_path, by_name=True)\n",
    "    \n",
    "\n",
    "'''\n",
    "train\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers \n",
    "    (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, \n",
    "    pass layers='heads' to the train() function.\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. \n",
    "    Simply pass layers=\"all to train all layers.\n",
    "'''\n",
    "\n",
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=40, \n",
    "            layers='all')\n",
    "\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=80,\n",
    "            layers='all')\n",
    "\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE/10,\n",
    "            epochs=120,\n",
    "            layers='all')\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE/20,\n",
    "            epochs=200,\n",
    "            layers='all')\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE/40,\n",
    "            epochs=280,\n",
    "            layers='all')\n",
    "\n",
    "## Fine tune all layers\n",
    "## Passing layers=\"all\" trains all layers. You can also \n",
    "## pass a regular expression to select which layers to\n",
    "## train by name pattern.\n",
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=config.LEARNING_RATE/10,\n",
    "#             epochs=200, \n",
    "#             layers=\"all\")\n",
    "\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=config.LEARNING_RATE/20,\n",
    "#             epochs=300,\n",
    "#             layers='all')\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=config.LEARNING_RATE/50,\n",
    "#             epochs=400,\n",
    "#             layers='all')\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=config.LEARNING_RATE/100,\n",
    "#             epochs=500,\n",
    "#             layers='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sUiap03RbPN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Y_KWxQnRbF9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIC2J_N-RbDA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACOkYvfky3BW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SQR4Rl2L2ZT"
   },
   "source": [
    "# TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUN7Z90I6dmJ"
   },
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Training dataset.\n",
    "    dataset_train = BalloonDataset()\n",
    "    dataset_train.load_balloon(SAMPLES_DIR, \"train-images\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = BalloonDataset()\n",
    "    dataset_val.load_balloon(SAMPLES_DIR, \"val-images\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    # *** This training schedule is an example. Update to your needs ***\n",
    "    # Since we're using a very small dataset, and starting from\n",
    "    # COCO trained weights, we don't need to train too long. Also,\n",
    "    # no need to train all layers, just the heads should do it.\n",
    "\n",
    "\n",
    "    # log_dir1=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # #tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir1, histogram_freq=1)\n",
    "\n",
    "    # tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir1,\n",
    "    #                                     histogram_freq=1, write_graph=True, write_images=False)\n",
    "    # custom_callbacks = [tensorboard_callback],\n",
    "\n",
    "\n",
    "    print(\"Training network heads\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=500,\n",
    "                layers='heads')  \n",
    "    \n",
    "#     model.save('64x3-CNN.model')\n",
    "\n",
    "# checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGEd6luK6e20"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('Train')\n",
    "    \n",
    "    config = BalloonConfig()\n",
    "    \n",
    "    model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=DEFAULT_LOGS_DIR)\n",
    "    \n",
    "    weights_path = COCO_WEIGHTS_PATH\n",
    "#     COCO_WEIGHTS_PATH = '../../../mask_rcnn_coco.h5'\n",
    "    \n",
    "    # Find last trained weights\n",
    "    # weights_path = model.find_last()[1]\n",
    "    \n",
    "    \n",
    "    model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    \n",
    "    train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftmEInzgLrN1"
   },
   "source": [
    "## SAVING MODEL STARTS INTO JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "executionInfo": {
     "elapsed": 3541,
     "status": "error",
     "timestamp": 1612596387029,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh5.googleusercontent.com/-1cfglh_j7Tw/AAAAAAAAAAI/AAAAAAAAQL0/uT7Ehc7X2bI/s64/photo.jpg",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "2RnMeo7Nwirz",
    "outputId": "8c69caa1-add0-49a4-f30f-bf867fb3e66e"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f75a00d877fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_fruits.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "history = model.keras_model.history.history\n",
    "with open('train_fruits200.json', 'w') as fp:\n",
    "    json.dump(history, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fby3t37JKx6E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "executionInfo": {
     "elapsed": 3548,
     "status": "error",
     "timestamp": 1612596387045,
     "user": {
      "displayName": "Kiprono Elijah Koech",
      "photoUrl": "https://lh5.googleusercontent.com/-1cfglh_j7Tw/AAAAAAAAAAI/AAAAAAAAQL0/uT7Ehc7X2bI/s64/photo.jpg",
      "userId": "06588571517751136640"
     },
     "user_tz": -120
    },
    "id": "Bj0y-tu_v4Da",
    "outputId": "751522ef-e8a9-4a05-eb92-81333c94a14d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6bc40cf79fdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m131\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"valid loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(200)\n",
    "plt.subplot(131)\n",
    "plt.plot(epochs, history['loss'], label=\"train loss\")\n",
    "plt.plot(epochs, history['val_loss'], label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.subplot(132)\n",
    "plt.plot(epochs, history['mrcnn_class_loss'], label=\"train class loss\")\n",
    "plt.plot(epochs, history['val_mrcnn_class_loss'], label=\"valid class loss\")\n",
    "plt.legend()\n",
    "plt.subplot(133)\n",
    "plt.plot(epochs, history['mrcnn_mask_loss'], label=\"train mask loss\")\n",
    "plt.plot(epochs, history['val_mrcnn_mask_loss'], label=\"valid mask loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hZcFXigDq5G"
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, history['loss'], label=\"train loss\")\n",
    "plt.plot(epochs, history['val_loss'], label=\"valid loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImvFjmyODq7s"
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, history['mrcnn_class_loss'], label=\"train class loss\")\n",
    "plt.plot(epochs, history['val_mrcnn_class_loss'], label=\"valid class loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FoxVCUpkhbpg"
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, history['mrcnn_mask_loss'], label=\"train mask loss\")\n",
    "plt.plot(epochs, history['val_mrcnn_mask_loss'], label=\"valid mask loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aA7jpK_5hhBZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZ8e6BCbhhEo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYjrQehsLg2P"
   },
   "source": [
    "# TESTING THE MODEL ON SAMPLE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdB3UOEN6e5U"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Local path to trained weights file\n",
    "#ROOT_DIR = '/content/gdrive/My Drive/Balloon/trained/balloon20191026T0853'\n",
    "COCO_MODEL_PATH = \"./assets/logs/all20201229T1052/mask_rcnn_all_0200.h5\"\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "# Directory of images to run detection on\n",
    "#IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ivA4aX76e7s"
   },
   "outputs": [],
   "source": [
    "config = BalloonConfig()\n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=\"./trained\", config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_e43l9g6fAa"
   },
   "outputs": [],
   "source": [
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "class_names = ['BG', 'fruit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPEDfUTj6fDV"
   },
   "outputs": [],
   "source": [
    "file_names = [i for i in os.listdir(os.path.join(DATA_DIR,\"val-images\")) if i.startswith(\"_MG_\")]\n",
    "for _ in range(5):\n",
    "    # Load a random image from the images folder\n",
    "    file_ = random.choice(file_names)\n",
    "    # file_ = \"20151124T031733.705044_i2070j1370.png\"\n",
    "    print(file_)\n",
    "    image = skimage.io.imread(os.path.join(DATA_DIR+\"/val-images\", file_))\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(image)\n",
    " \n",
    "    # Run detection/'\n",
    "    results = model.detect([image], verbose=1)\n",
    "\n",
    "    # Visualize results\n",
    "    r = results[0]\n",
    "    display_ = visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                class_names, r['scores'])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UF2XpM7d6e-s"
   },
   "outputs": [],
   "source": [
    "r[\"rois\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caSSewD71_Tb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2EZFMw11_W-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08se4Atb1_aE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6UbrSZTm1_df"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "fruits-train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
